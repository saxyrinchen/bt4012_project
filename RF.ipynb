{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from random import seed,sample\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# feature scaling & OHE\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler # data encoders\n",
    "\n",
    "# moodels \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# evaluation metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, roc_auc_score, confusion_matrix\n",
    "\n",
    "# resampling techniques for imbalanced data\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE #\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# formatting \n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../X_train.csv')\n",
    "X_test = pd.read_csv('../X_test.csv')\n",
    "y_train = pd.read_csv('../y_train.csv')\n",
    "y_test = pd.read_csv('../y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: \n",
      " Accuracy: 0.8842688481048876\n",
      " Precision: 0.03471159527885941\n",
      " Recall: 0.7913644214162349\n",
      " F1-Score: 0.06650603808639108\n",
      " ROC AUC: 0.8380598932978747\n"
     ]
    }
   ],
   "source": [
    "# Define categorical and numerical features\n",
    "categorical_cols = ['category', 'gender', 'state', 'job', 'day_of_week']\n",
    "numerical_cols = ['amount(usd)', 'lat', 'long', 'merch_lat', 'merch_long', 'hour_of_day', 'age']\n",
    "\n",
    "# Create the preprocessing for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combine preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Create a pipeline with preprocessing and the model\n",
    "model = ImbPipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('smote', SMOTE(random_state=42)),\n",
    "                           ('classifier', LogisticRegression(random_state=42))])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics on the validation set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Output the metrics\n",
    "print(f'Validation Metrics: \\n Accuracy: {accuracy}\\n Precision: {precision}\\n Recall: {recall}\\n F1-Score: {f1}\\n ROC AUC: {roc_auc}')\n",
    "\n",
    "# If the performance is satisfactory, you can proceed to evaluate the model on the test set in a similar fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest \n",
    "#### 2.1 Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics with Random Forest: \n",
      " Accuracy: 0.9984\n",
      " Precision: 0.9864\n",
      " Recall: 0.7016\n",
      " F1-Score: 0.8199\n",
      " ROC AUC: 0.9815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming preprocessor is already defined as before\n",
    "# Update the model in the pipeline to RandomForestClassifier\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the probabilities for ROC AUC\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate evaluation metrics on the validation set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba) # Use probabilities for ROC AUC\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Validation Metrics with Random Forest: \\n Accuracy: {accuracy:.4f}\\n Precision: {precision:.4f}\\n Recall: {recall:.4f}\\n F1-Score: {f1:.4f}\\n ROC AUC: {roc_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Random Under-Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
