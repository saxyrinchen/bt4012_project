{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from random import seed,sample\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import RandomUnderSampler # Undersampling for Unbalanced Data\n",
    "from imblearn.over_sampling import SMOTE # Oversampling for Unbalanced Data\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler # Data Encoders\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv('../X_train.csv')\n",
    "# X_test = pd.read_csv('../X_test.csv')\n",
    "# y_train = pd.read_csv('../y_train.csv')\n",
    "# y_test = pd.read_csv('../y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv('/Users/jolenelee/Downloads/y_new.csv')\n",
    "X = pd.read_csv('/Users/jolenelee/Downloads/X_job_categories (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1852394 entries, 0 to 1852393\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Dtype  \n",
      "---  ------          -----  \n",
      " 0   category        object \n",
      " 1   amount(usd)     float64\n",
      " 2   gender          object \n",
      " 3   state           object \n",
      " 4   lat             float64\n",
      " 5   long            float64\n",
      " 6   job             object \n",
      " 7   merch_lat       float64\n",
      " 8   merch_long      float64\n",
      " 9   hour_of_day     int64  \n",
      " 10  day_of_week     object \n",
      " 11  age             int64  \n",
      " 12  job_categories  object \n",
      "dtypes: float64(5), int64(2), object(6)\n",
      "memory usage: 183.7+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1852394 entries, 0 to 1852393\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Dtype\n",
      "---  ------    -----\n",
      " 0   is_fraud  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 14.1 MB\n"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category          0\n",
      "amount(usd)       0\n",
      "gender            0\n",
      "state             0\n",
      "lat               0\n",
      "long              0\n",
      "job               0\n",
      "merch_lat         0\n",
      "merch_long        0\n",
      "hour_of_day       0\n",
      "day_of_week       0\n",
      "age               0\n",
      "job_categories    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_values = X.isnull().sum()\n",
    "\n",
    "# Display the count of null values for each column\n",
    "print(null_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1852394, 13)\n",
      "y shape: (1852394, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified sampling for imbalanced classes\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42) # X_train 80% of total\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, stratify=y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1481915, 13)\n",
      "X_val shape: (185239, 13)\n",
      "X_test shape: (185240, 13)\n",
      "y_train shape: (1481915, 1)\n",
      "y_val shape: (185239, 1)\n",
      "y_test shape: (185240, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of X_train, X_val, X_test, y_train, y_val, y_test\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features below only, we don't scale the hour_of_day since the values are already within a similar range and have a clear numerical interpretation (hours of the day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 185240 entries, 1519040 to 419836\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   category        185240 non-null  object \n",
      " 1   amount(usd)     185240 non-null  float64\n",
      " 2   gender          185240 non-null  object \n",
      " 3   state           185240 non-null  object \n",
      " 4   lat             185240 non-null  float64\n",
      " 5   long            185240 non-null  float64\n",
      " 6   job             185240 non-null  object \n",
      " 7   merch_lat       185240 non-null  float64\n",
      " 8   merch_long      185240 non-null  float64\n",
      " 9   hour_of_day     185240 non-null  int64  \n",
      " 10  day_of_week     185240 non-null  object \n",
      " 11  age             185240 non-null  float64\n",
      " 12  job_categories  185240 non-null  object \n",
      "dtypes: float64(6), int64(1), object(6)\n",
      "memory usage: 19.8+ MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_to_scale = [\"amount(usd)\", \"lat\", \"long\", \"merch_lat\", \"merch_long\", \"age\"]\n",
    "\n",
    "\n",
    "# Initialize the StandardScaler and fit/transform on numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the scaler on the selected features in your training data\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "\n",
    "# Transform the same selected features in validation data using the same scaler\n",
    "X_val_scaled = X_val.copy()\n",
    "X_val_scaled[features_to_scale] = scaler.transform(X_val[features_to_scale])\n",
    "\n",
    "# Transform the same selected features in test data using the same scaler\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>amount(usd)</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>job</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>age</th>\n",
       "      <th>job_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1519040</th>\n",
       "      <td>shopping_pos</td>\n",
       "      <td>-0.437322</td>\n",
       "      <td>F</td>\n",
       "      <td>NY</td>\n",
       "      <td>1.250101</td>\n",
       "      <td>1.206416</td>\n",
       "      <td>Surveyor, land/geomatics</td>\n",
       "      <td>1.209293</td>\n",
       "      <td>1.253763</td>\n",
       "      <td>8</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1.194640</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464165</th>\n",
       "      <td>shopping_pos</td>\n",
       "      <td>-0.436237</td>\n",
       "      <td>F</td>\n",
       "      <td>MO</td>\n",
       "      <td>-0.349648</td>\n",
       "      <td>-0.276857</td>\n",
       "      <td>Production manager</td>\n",
       "      <td>-0.534726</td>\n",
       "      <td>-0.340737</td>\n",
       "      <td>18</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>-0.702057</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119190</th>\n",
       "      <td>food_dining</td>\n",
       "      <td>-0.394625</td>\n",
       "      <td>F</td>\n",
       "      <td>TX</td>\n",
       "      <td>-1.617997</td>\n",
       "      <td>-0.347429</td>\n",
       "      <td>Building surveyor</td>\n",
       "      <td>-1.452376</td>\n",
       "      <td>-0.415589</td>\n",
       "      <td>14</td>\n",
       "      <td>Friday</td>\n",
       "      <td>-1.276813</td>\n",
       "      <td>C2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567844</th>\n",
       "      <td>shopping_pos</td>\n",
       "      <td>-0.383903</td>\n",
       "      <td>M</td>\n",
       "      <td>MS</td>\n",
       "      <td>-0.997472</td>\n",
       "      <td>-0.019935</td>\n",
       "      <td>Chartered public finance accountant</td>\n",
       "      <td>-1.033834</td>\n",
       "      <td>0.035471</td>\n",
       "      <td>14</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>-1.449240</td>\n",
       "      <td>C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244301</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>-0.433110</td>\n",
       "      <td>M</td>\n",
       "      <td>CA</td>\n",
       "      <td>-0.950562</td>\n",
       "      <td>-1.896804</td>\n",
       "      <td>Learning mentor</td>\n",
       "      <td>-1.097084</td>\n",
       "      <td>-1.871424</td>\n",
       "      <td>10</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>1.079689</td>\n",
       "      <td>C1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category  amount(usd) gender state       lat      long  \\\n",
       "1519040   shopping_pos    -0.437322      F    NY  1.250101  1.206416   \n",
       "464165    shopping_pos    -0.436237      F    MO -0.349648 -0.276857   \n",
       "119190     food_dining    -0.394625      F    TX -1.617997 -0.347429   \n",
       "1567844   shopping_pos    -0.383903      M    MS -0.997472 -0.019935   \n",
       "1244301  entertainment    -0.433110      M    CA -0.950562 -1.896804   \n",
       "\n",
       "                                         job  merch_lat  merch_long  \\\n",
       "1519040             Surveyor, land/geomatics   1.209293    1.253763   \n",
       "464165                    Production manager  -0.534726   -0.340737   \n",
       "119190                     Building surveyor  -1.452376   -0.415589   \n",
       "1567844  Chartered public finance accountant  -1.033834    0.035471   \n",
       "1244301                      Learning mentor  -1.097084   -1.871424   \n",
       "\n",
       "         hour_of_day day_of_week       age job_categories  \n",
       "1519040            8     Tuesday  1.194640             C2  \n",
       "464165            18     Tuesday -0.702057             C3  \n",
       "119190            14      Friday -1.276813             C2  \n",
       "1567844           14     Tuesday -1.449240             C3  \n",
       "1244301           10     Tuesday  1.079689             C1  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of unqiue sates:  51\n",
      "no of unqiue categories:  14\n",
      "no of unqiue jobs:  488\n"
     ]
    }
   ],
   "source": [
    "unqiue_state = X_test_scaled['state'].nunique()\n",
    "unique_category = X_test_scaled['category'].nunique()\n",
    "unique_job = X_test_scaled['job'].nunique()\n",
    "\n",
    "print(\"no of unqiue sates: \", unqiue_state)\n",
    "print(\"no of unqiue categories: \", unique_category)\n",
    "print(\"no of unqiue jobs: \", unique_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then be one hot encoding some of our categorical variables to run a logistic regression model on X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize the OneHotEncoder with sparse=False and drop='first'\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "\n",
    "# Fit and transform the encoder on categorical columns in the training data\n",
    "X_train_encoded = encoder.fit_transform(X_train_scaled[['category', 'gender', 'day_of_week', 'job_categories']])\n",
    "\n",
    "# Transform the same columns in the validation data\n",
    "X_val_encoded = encoder.transform(X_val_scaled[['category', 'gender', 'day_of_week', 'job_categories']])\n",
    "\n",
    "# Transform the same columns in the test data\n",
    "X_test_encoded = encoder.transform(X_test_scaled[['category', 'gender', 'day_of_week', 'job_categories']])\n",
    "\n",
    "# Create DataFrames from the encoded arrays with appropriate column names\n",
    "encoded_columns = encoder.get_feature_names_out(['category', 'gender', 'day_of_week', 'job_categories'])\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoded_columns)\n",
    "X_val_encoded_df = pd.DataFrame(X_val_encoded, columns=encoded_columns)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = pd.concat([X_train_encoded_df.reset_index(drop=True), X_train_scaled[['age', 'lat', 'long', 'amount(usd)']].reset_index(drop=True)], axis=1)\n",
    "X_val_final = pd.concat([X_val_encoded_df.reset_index(drop=True), X_val_scaled[['age', 'lat', 'long', 'amount(usd)']].reset_index(drop=True)], axis=1)\n",
    "X_test_final = pd.concat([X_test_encoded_df.reset_index(drop=True), X_test_scaled[['age', 'lat', 'long', 'amount(usd)']].reset_index(drop=True)], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_final shape: (1481915, 32)\n",
      "X_val_final shape: (185239, 32)\n",
      "X_test_final shape: (185240, 32)\n",
      "y_train shape: (1481915, 1)\n",
      "y_val shape: (185239, 1)\n",
      "y_test shape: (185240, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of X_train, X_test, y_train, y_test\n",
    "print(\"X_train_final shape:\", X_train_final.shape)\n",
    "print(\"X_val_final shape:\", X_val_final.shape)\n",
    "print(\"X_test_final shape:\", X_test_final.shape)\n",
    "\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 555719 entries, 0 to 555718\n",
      "Data columns (total 32 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   category_food_dining     555719 non-null  float64\n",
      " 1   category_gas_transport   555719 non-null  float64\n",
      " 2   category_grocery_net     555719 non-null  float64\n",
      " 3   category_grocery_pos     555719 non-null  float64\n",
      " 4   category_health_fitness  555719 non-null  float64\n",
      " 5   category_home            555719 non-null  float64\n",
      " 6   category_kids_pets       555719 non-null  float64\n",
      " 7   category_misc_net        555719 non-null  float64\n",
      " 8   category_misc_pos        555719 non-null  float64\n",
      " 9   category_personal_care   555719 non-null  float64\n",
      " 10  category_shopping_net    555719 non-null  float64\n",
      " 11  category_shopping_pos    555719 non-null  float64\n",
      " 12  category_travel          555719 non-null  float64\n",
      " 13  gender_M                 555719 non-null  float64\n",
      " 14  day_of_week_Monday       555719 non-null  float64\n",
      " 15  day_of_week_Saturday     555719 non-null  float64\n",
      " 16  day_of_week_Sunday       555719 non-null  float64\n",
      " 17  day_of_week_Thursday     555719 non-null  float64\n",
      " 18  day_of_week_Tuesday      555719 non-null  float64\n",
      " 19  day_of_week_Wednesday    555719 non-null  float64\n",
      " 20  job_categories_C2        555719 non-null  float64\n",
      " 21  job_categories_C3        555719 non-null  float64\n",
      " 22  job_categories_C4        555719 non-null  float64\n",
      " 23  job_categories_C5        555719 non-null  float64\n",
      " 24  job_categories_C6        555719 non-null  float64\n",
      " 25  job_categories_C7        555719 non-null  float64\n",
      " 26  job_categories_C8        555719 non-null  float64\n",
      " 27  job_categories_C9        555719 non-null  float64\n",
      " 28  age                      555719 non-null  float64\n",
      " 29  lat                      555719 non-null  float64\n",
      " 30  long                     555719 non-null  float64\n",
      " 31  amount(usd)              555719 non-null  float64\n",
      "dtypes: float64(32)\n",
      "memory usage: 135.7 MB\n"
     ]
    }
   ],
   "source": [
    "X_test_final.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (Baseline Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to ensure that we have the same splits of the data every time. \n",
    "#We can ensure this by creating a KFold object, kf, and passing cv=kf instead of the more common cv=5.\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Recall scores are: [0.65136936 0.6565507  0.62250185 0.66913397 0.63091716]\n",
      "Average Cross Validation Recall score: 0.6460946088586583\n"
     ]
    }
   ],
   "source": [
    "score = cross_val_score(rf_classifier, X_train_final, y_train, cv=kf, scoring='recall')\n",
    "print(\"Cross Validation Recall scores are: {}\".format(score))\n",
    "print(\"Average Cross Validation Recall score: {}\".format(score.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model correctly identifies about 64.61% of the actual positive instances in the training data across different folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Initialize the imputer with the mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit and transform on X_train_final\n",
    "X_train_final = pd.DataFrame(imputer.fit_transform(X_train_final))\n",
    "\n",
    "# Transform X_val_final using the same imputer\n",
    "X_val_final = pd.DataFrame(imputer.fit_transform(X_val_final))\n",
    "\n",
    "# Transform X_test_final using the same imputer\n",
    "X_test_final = pd.DataFrame(imputer.transform(X_test_final))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_rf = RandomForestClassifier(random_state=42)\n",
    "baseline_rf.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = baseline_rf.predict(X_val_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[184168    106]\n",
      " [   326    639]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score, accuracy_score, roc_auc_score, average_precision_score\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "base_precision = precision_score(y_val, y_val_pred)\n",
    "base_recall = recall_score(y_val, y_val_pred)\n",
    "base_f1 = f1_score(y_val, y_val_pred)\n",
    "base_roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "base_pr_auc = average_precision_score(y_val, y_val_pred)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Under/Oversampling</td>\n",
       "      <td>0.662176</td>\n",
       "      <td>0.857718</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.56972</td>\n",
       "      <td>0.8308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Random Forest with    Recall  Precision  F1 Score   PR AUC  ROC_AUC\n",
       "0  No Under/Oversampling  0.662176   0.857718  0.747368  0.56972   0.8308"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(base_recall, base_precision, base_f1, base_pr_auc, base_roc_auc)]\n",
    "\n",
    "rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'PR AUC', 'ROC_AUC'])\n",
    "rf_score.insert(0, 'Random Forest with', 'No Under/Oversampling')\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: 66.22% - This indicates that the model correctly identified about 66.22% of the actual positive cases (frauds). A higher recall is generally desirable in fraud detection to capture more of the fraudulent transactions.\n",
    "\n",
    "Precision: 85.77% - This shows that out of all the predicted positive cases, approximately 85.77% were true positives. A higher precision means fewer false positives, which is beneficial for avoiding unnecessary interventions.\n",
    "\n",
    "F1 Score: 74.74% - The F1 score is the harmonic mean of precision and recall. It provides a balance between precision and recall. A higher F1 score is generally preferred, and this value indicates a reasonably balanced performance.\n",
    "\n",
    "PR AUC (Precision-Recall AUC): 56.97% - This metric measures the area under the precision-recall curve. It's another way to assess the trade-off between precision and recall. A higher PR AUC is desirable.\n",
    "\n",
    "ROC AUC (Receiver Operating Characteristic AUC): 83.08% - ROC AUC measures the area under the ROC curve, which evaluates the model's performance across different thresholds. An ROC AUC of 83.08% is reasonable, indicating good discrimination between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest with Random Over Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "# define oversampling strategy\n",
    "ros = RandomOverSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and apply the transform\n",
    "X_over, y_over = ros.fit_resample(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "random_overs_pipeline = make_pipeline(RandomOverSampler(random_state=42), \n",
    "                              RandomForestClassifier(n_estimators=100, random_state=13))\n",
    "#cross_val_score(random_overs_pipeline, X_train, y_train, scoring='recall', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Recall Scores are: [0.68911917 0.70392302 0.67283494 0.70836417 0.67011834]\n",
      "Average Cross Validation Recall score: 0.6888719291867956\n"
     ]
    }
   ],
   "source": [
    "score2 = cross_val_score(random_overs_pipeline, X_train_final, y_train, scoring='recall', cv=kf)\n",
    "print(\"Cross Validation Recall Scores are: {}\".format(score2))\n",
    "print(\"Average Cross Validation Recall score: {}\".format(score2.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " model correctly identifies about 68.89% of the actual positive instances in the training data across different folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genuine: 1474194 / 50.0 % of the dataset\n",
      "Frauds: 1474194 / 50.0 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "print('Genuine:', y_over.value_counts()[0], '/', round(y_over.value_counts()[0]/len(y_over) * 100,2), '% of the dataset')\n",
    "print('Frauds:', y_over.value_counts()[1], '/',round(y_over.value_counts()[1]/len(y_over) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;randomoversampler&#x27;, RandomOverSampler(random_state=42)),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(random_state=13))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomoversampler&#x27;, RandomOverSampler(random_state=42)),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(random_state=13))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler(random_state=42)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=13)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('randomoversampler', RandomOverSampler(random_state=42)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(random_state=13))])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_overs_pipeline.fit(X_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred_oversampled = random_overs_pipeline.predict(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[184108    166]\n",
      " [   280    685]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val, y_val_pred_oversampled)\n",
    "\n",
    "over_rf_Recall = recall_score(y_val, y_val_pred_oversampled)\n",
    "over_rf_Precision = precision_score(y_val, y_val_pred_oversampled)\n",
    "over_rf_f1 = f1_score(y_val, y_val_pred_oversampled)\n",
    "over_rf_accuracy = accuracy_score(y_val, y_val_pred_oversampled)\n",
    "over_roc = roc_auc_score(y_val, y_val_pred_oversampled)\n",
    "over_prauc = average_precision_score(y_val, y_val_pred_oversampled)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.709845</td>\n",
       "      <td>0.804935</td>\n",
       "      <td>0.754405</td>\n",
       "      <td>0.572891</td>\n",
       "      <td>0.854472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Random Forest with    Recall  Precision  F1 Score    PR AUC   ROC_AUC\n",
       "0  Random Oversampling  0.709845   0.804935  0.754405  0.572891  0.854472"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(over_rf_Recall, over_rf_Precision, over_rf_f1, over_prauc, over_roc)]\n",
    "\n",
    "over_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'PR AUC', 'ROC_AUC'])\n",
    "over_rf_score.insert(0, 'Random Forest with', 'Random Oversampling')\n",
    "over_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: 70.98% - The model with oversampling has a higher recall compared to the model without oversampling. This indicates an improvement in the ability to correctly identify positive cases (frauds).\n",
    "\n",
    "Precision: 80.49% - The precision is slightly lower than the model without oversampling, but it's still relatively high. This means that out of all the predicted positive cases, around 80.49% were true positives.\n",
    "\n",
    "F1 Score: 75.44% - The F1 score is also higher than the model without oversampling, indicating a better balance between precision and recall.\n",
    "\n",
    "PR AUC (Precision-Recall AUC): 57.29% - The PR AUC has improved slightly, indicating a better precision-recall trade-off.\n",
    "\n",
    "ROC AUC (Receiver Operating Characteristic AUC): 85.45% - The ROC AUC has also increased, indicating improved discrimination between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch for Oversampling, tuning of hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [6, 10, 12],\n",
    "    'random_state': [13]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;randomoversampler&#x27;,\n",
       "                                        RandomOverSampler()),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={&#x27;randomforestclassifier__max_depth&#x27;: [6, 10, 12],\n",
       "                         &#x27;randomforestclassifier__n_estimators&#x27;: [50, 100, 200],\n",
       "                         &#x27;randomforestclassifier__random_state&#x27;: [13]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;randomoversampler&#x27;,\n",
       "                                        RandomOverSampler()),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={&#x27;randomforestclassifier__max_depth&#x27;: [6, 10, 12],\n",
       "                         &#x27;randomforestclassifier__n_estimators&#x27;: [50, 100, 200],\n",
       "                         &#x27;randomforestclassifier__random_state&#x27;: [13]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomoversampler&#x27;, RandomOverSampler()),\n",
       "                (&#x27;randomforestclassifier&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomOverSampler</label><div class=\"sk-toggleable__content\"><pre>RandomOverSampler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('randomoversampler',\n",
       "                                        RandomOverSampler()),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             param_grid={'randomforestclassifier__max_depth': [6, 10, 12],\n",
       "                         'randomforestclassifier__n_estimators': [50, 100, 200],\n",
       "                         'randomforestclassifier__random_state': [13]},\n",
       "             return_train_score=True, scoring='f1')"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params = {'randomforestclassifier__' + key: params[key] for key in params}\n",
    "grid_over_rf = GridSearchCV(random_overs_pipeline, param_grid=new_params, cv=kf, scoring='f1',\n",
    "                        return_train_score=True)\n",
    "grid_over_rf.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.pipeline import Pipeline, make_pipeline\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# # Define the pipeline\n",
    "# random_overs_pipeline = make_pipeline(RandomOverSampler(), \n",
    "#                                        RandomForestClassifier())\n",
    "\n",
    "# # Define the parameters for the RandomizedSearchCV\n",
    "# params = {\n",
    "#     'randomforestclassifier__n_estimators': [50, 100, 200],\n",
    "#     'randomforestclassifier__max_depth': [6, 10, 12],\n",
    "#     'randomforestclassifier__random_state': [13]\n",
    "# }\n",
    "\n",
    "# # Run the RandomizedSearchCV\n",
    "# random_search_overs = RandomizedSearchCV(random_overs_pipeline, param_distributions=params, n_iter=5, scoring='f1', cv=kf, random_state=42)\n",
    "# random_search_overs.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'randomforestclassifier__max_depth': 12, 'randomforestclassifier__n_estimators': 100, 'randomforestclassifier__random_state': 13}\n",
      "Best score: 0.4187735423863095\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:', grid_over_rf.best_params_)\n",
    "print('Best score:', grid_over_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_over2 = grid_over_rf.best_estimator_.named_steps['randomforestclassifier'].predict(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[182098   2176]\n",
      " [   135    830]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val, y_pred_over2)\n",
    "\n",
    "over2_rf_Recall = recall_score(y_val, y_pred_over2)\n",
    "over2_rf_Precision = precision_score(y_val, y_pred_over2)\n",
    "over2_rf_f1 = f1_score(y_val, y_pred_over2)\n",
    "over2_rf_accuracy = accuracy_score(y_val, y_pred_over2)\n",
    "over2_rf_roc = roc_auc_score(y_val, y_pred_over2)\n",
    "over2_rf_prauc = average_precision_score(y_val, y_pred_over2)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Oversampling using GridSearch</td>\n",
       "      <td>0.860104</td>\n",
       "      <td>0.276114</td>\n",
       "      <td>0.418031</td>\n",
       "      <td>0.238216</td>\n",
       "      <td>0.924148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Random Forest with    Recall  Precision  F1 Score  \\\n",
       "0  Random Oversampling using GridSearch  0.860104   0.276114  0.418031   \n",
       "\n",
       "     PR AUC   ROC_AUC  \n",
       "0  0.238216  0.924148  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(over2_rf_Recall, over2_rf_Precision, over2_rf_f1, over2_rf_prauc, over2_rf_roc)]\n",
    "\n",
    "over2_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'PR AUC', 'ROC_AUC'])\n",
    "over2_rf_score.insert(0, 'Random Forest with', 'Random Oversampling using GridSearch')\n",
    "over2_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: 86.01% - The model with oversampling and grid search for hyperparameter tuning has a significantly higher recall compared to the model without grid search. This indicates a substantial improvement in correctly identifying positive cases (frauds).\n",
    "\n",
    "Precision: 27.61% - The precision is lower compared to the model without grid search, meaning that out of all the predicted positive cases, a smaller percentage were true positives. This trade-off is often observed in imbalanced datasets.\n",
    "\n",
    "F1 Score: 41.80% - The F1 score is a balance between precision and recall. While recall is high, the lower precision contributes to a lower F1 score compared to the model without grid search.\n",
    "\n",
    "PR AUC (Precision-Recall AUC): 23.82% - The PR AUC is lower, indicating a more conservative precision-recall trade-off.\n",
    "\n",
    "ROC AUC (Receiver Operating Characteristic AUC): 92.41% - The ROC AUC has increased compared to the model without grid search, suggesting improved discrimination between classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# define oversampling strategy\n",
    "rus = RandomUnderSampler(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and apply the transform\n",
    "X_under, y_under = rus.fit_resample(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genuine: 7721 / 50.0 % of the dataset\n",
      "Frauds: 7721 / 50.0 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "print('Genuine:', y_under.value_counts()[0], '/', round(y_under.value_counts()[0]/len(y_under) * 100,2), '% of the dataset')\n",
    "print('Frauds:', y_under.value_counts()[1], '/',round(y_under.value_counts()[1]/len(y_under) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "random_unders_pipeline = make_pipeline(RandomUnderSampler(random_state=42), \n",
    "                              RandomForestClassifier(n_estimators=100, random_state=13))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Recall Scores are: [0.94300518 0.9511473  0.96299038 0.96225019 0.94230769]\n",
      "Average Cross Validation Recall score: 0.9523401468997325\n"
     ]
    }
   ],
   "source": [
    "score3 = cross_val_score(random_unders_pipeline, X_train_final, y_train, scoring='recall', cv=kf)\n",
    "print(\"Cross Validation Recall Scores are: {}\".format(score3))\n",
    "print(\"Average Cross Validation Recall score: {}\".format(score3.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " model correctly identifies about 95.23% of the actual positive instances in the training data across different folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;randomundersampler&#x27;, RandomUnderSampler(random_state=42)),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(random_state=13))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomundersampler&#x27;, RandomUnderSampler(random_state=42)),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(random_state=13))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=13)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('randomundersampler', RandomUnderSampler(random_state=42)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(random_state=13))])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_unders_pipeline.fit(X_under, y_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred_undersampled = random_unders_pipeline.predict(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[178528   5746]\n",
      " [    38    927]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val, y_val_pred_undersampled)\n",
    "\n",
    "under_rf_Recall = recall_score(y_val, y_val_pred_undersampled)\n",
    "under_rf_Precision = precision_score(y_val, y_val_pred_undersampled)\n",
    "under_rf_f1 = f1_score(y_val, y_val_pred_undersampled)\n",
    "under_rf_accuracy = accuracy_score(y_val, y_val_pred_undersampled)\n",
    "under_roc = roc_auc_score(y_val, y_val_pred_undersampled)\n",
    "under_prauc = average_precision_score(y_val, y_val_pred_undersampled)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.960622</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.242734</td>\n",
       "      <td>0.133653</td>\n",
       "      <td>0.96472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Random Forest with    Recall  Precision  F1 Score    PR AUC  ROC_AUC\n",
       "0  Random Undersampling  0.960622   0.138918  0.242734  0.133653  0.96472"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(under_rf_Recall, under_rf_Precision, under_rf_f1, under_prauc, under_roc)]\n",
    "\n",
    "under_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'PR AUC', 'ROC_AUC'])\n",
    "under_rf_score.insert(0, 'Random Forest with', 'Random Undersampling')\n",
    "under_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random undersampling has significantly improved recall; however, it has led to a drop in precision. It's essential to balance between precision and recall, as a model with high recall and low precision may flag too many false positives. \n",
    "\n",
    "Recall: 96.06% - The model with random undersampling has an extremely high recall, indicating that it is effective in capturing a large proportion of the actual positive cases (frauds). This is a significant improvement over the models with oversampling.\n",
    "\n",
    "Precision: 13.89% - The precision is relatively low, indicating that out of all the predicted positive cases, only a small percentage are true positives. This trade-off between precision and recall is typical in imbalanced datasets.\n",
    "\n",
    "F1 Score: 24.27% - The F1 score, which balances precision and recall, is higher than the model with oversampling but still reflects the challenge of achieving both high precision and high recall simultaneously.\n",
    "\n",
    "PR AUC (Precision-Recall AUC): 13.37% - The PR AUC is low, suggesting a conservative precision-recall trade-off.\n",
    "\n",
    "ROC AUC (Receiver Operating Characteristic AUC): 96.47% - The ROC AUC is high, indicating good overall performance in distinguishing between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch for RandomUndersampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;randomundersampler&#x27;,\n",
       "                                        RandomUnderSampler(random_state=42)),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=13))]),\n",
       "             param_grid={&#x27;randomforestclassifier__max_depth&#x27;: [6, 10, 12],\n",
       "                         &#x27;randomforestclassifier__n_estimators&#x27;: [50, 100, 200],\n",
       "                         &#x27;randomforestclassifier__random_state&#x27;: [13]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[(&#x27;randomundersampler&#x27;,\n",
       "                                        RandomUnderSampler(random_state=42)),\n",
       "                                       (&#x27;randomforestclassifier&#x27;,\n",
       "                                        RandomForestClassifier(random_state=13))]),\n",
       "             param_grid={&#x27;randomforestclassifier__max_depth&#x27;: [6, 10, 12],\n",
       "                         &#x27;randomforestclassifier__n_estimators&#x27;: [50, 100, 200],\n",
       "                         &#x27;randomforestclassifier__random_state&#x27;: [13]},\n",
       "             return_train_score=True, scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;randomundersampler&#x27;, RandomUnderSampler(random_state=42)),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(random_state=13))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomUnderSampler</label><div class=\"sk-toggleable__content\"><pre>RandomUnderSampler(random_state=42)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=13)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('randomundersampler',\n",
       "                                        RandomUnderSampler(random_state=42)),\n",
       "                                       ('randomforestclassifier',\n",
       "                                        RandomForestClassifier(random_state=13))]),\n",
       "             param_grid={'randomforestclassifier__max_depth': [6, 10, 12],\n",
       "                         'randomforestclassifier__n_estimators': [50, 100, 200],\n",
       "                         'randomforestclassifier__random_state': [13]},\n",
       "             return_train_score=True, scoring='f1')"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_params = {'randomforestclassifier__' + key: params[key] for key in params}\n",
    "grid_under2_rf = GridSearchCV(random_unders_pipeline, param_grid=new_params, cv=kf, scoring='f1',\n",
    "                        return_train_score=True)\n",
    "grid_under2_rf.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__n_estimators': 100, 'randomforestclassifier__random_state': 13}\n",
      "Best score: 0.3469552612767547\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:', grid_under2_rf.best_params_)\n",
    "print('Best score:', grid_under2_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best parameters for undersampling from your grid search\n",
    "# best_params_under2 = {\n",
    "#     'max_depth': 12,\n",
    "#     'n_estimators': 200,\n",
    "#     'random_state': 13\n",
    "# }\n",
    "\n",
    "# # Create a RandomForestClassifier with the best parameters for undersampling\n",
    "# best_rf_under2 = RandomForestClassifier(**best_params_under2)\n",
    "\n",
    "# # Fit the classifier on your training data for undersampling\n",
    "# best_rf_under2.fit(X_under, y_under)\n",
    "\n",
    "# # Make predictions on your test set for undersampling\n",
    "# y_pred_under2 = best_rf_under2.predict(X_val_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_under2 = grid_under2_rf.best_estimator_.named_steps['randomforestclassifier'].predict(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[181392   2882]\n",
      " [   150    815]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val, y_pred_under2)\n",
    "\n",
    "under2_rf_Recall = recall_score(y_val, y_pred_under2)\n",
    "under2_rf_Precision = precision_score(y_val, y_pred_under2)\n",
    "under2_rf_f1 = f1_score(y_val, y_pred_under2)\n",
    "under2_rf_accuracy = accuracy_score(y_val, y_pred_under2)\n",
    "under2_rf_roc = roc_auc_score(y_val, y_pred_under2)\n",
    "under2_rf_prauc = average_precision_score(y_val, y_pred_over2)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random undersampling using GridSearch</td>\n",
       "      <td>0.84456</td>\n",
       "      <td>0.220449</td>\n",
       "      <td>0.349635</td>\n",
       "      <td>0.238216</td>\n",
       "      <td>0.91446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Random Forest with   Recall  Precision  F1 Score  \\\n",
       "0  Random undersampling using GridSearch  0.84456   0.220449  0.349635   \n",
       "\n",
       "     PR AUC  ROC_AUC  \n",
       "0  0.238216  0.91446  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(under2_rf_Recall, under2_rf_Precision, under2_rf_f1, under2_rf_prauc, under2_rf_roc)]\n",
    "\n",
    "under2_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'PR AUC', 'ROC_AUC'])\n",
    "under2_rf_score.insert(0, 'Random Forest with', 'Random undersampling using GridSearch')\n",
    "under2_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: 84.46% - The model with random undersampling and grid search for hyperparameter tuning shows a high recall, indicating that it is effective in capturing a large proportion of the actual positive cases (frauds). This is a substantial improvement over the basic Random Undersampling model.\n",
    "\n",
    "Precision: 22.04% - The precision is higher compared to the basic Random Undersampling model, indicating that a larger proportion of the predicted positive cases are true positives.\n",
    "\n",
    "F1 Score: 34.96% - The F1 score, which balances precision and recall, is improved compared to the basic Random Undersampling model.\n",
    "\n",
    "PR AUC (Precision-Recall AUC): 23.82% - The PR AUC is low, suggesting a conservative precision-recall trade-off.\n",
    "\n",
    "ROC AUC (Receiver Operating Characteristic AUC): 91.45% - The ROC AUC is slightly lower compared to the basic Random Undersampling model but still indicates good discrimination between classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote_pipeline = make_pipeline(SMOTE(random_state=42), \n",
    "                              RandomForestClassifier(n_estimators=100, random_state=13))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Recall Scores are: [0.77646188 0.76239822 0.73871207 0.78756477 0.75887574]\n",
      "Average Cross Validation Recall score: 0.7648025350496455\n"
     ]
    }
   ],
   "source": [
    "score4 = cross_val_score(smote_pipeline, X_train_final, y_train, scoring='recall', cv=kf)\n",
    "print(\"Cross Validation Recall Scores are: {}\".format(score4))\n",
    "print(\"Average Cross Validation Recall score: {}\".format(score4.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " model correctly identifies about 76.48% of the actual positive instances in the training data across different folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(random_state=13))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
       "                (&#x27;randomforestclassifier&#x27;,\n",
       "                 RandomForestClassifier(random_state=13))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(random_state=42)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=13)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('smote', SMOTE(random_state=42)),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(random_state=13))])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "smote_pipeline.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_smote = smote_pipeline.predict(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[183971    303]\n",
      " [   234    731]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val, y_pred_smote)\n",
    "\n",
    "smote_rf_Recall = recall_score(y_val, y_pred_smote)\n",
    "smote_rf_Precision = precision_score(y_val, y_pred_smote)\n",
    "smote_rf_f1 = f1_score(y_val, y_pred_smote)\n",
    "smote_rf_accuracy = accuracy_score(y_val, y_pred_smote)\n",
    "smote_rf_rocauc = roc_auc_score(y_val, y_pred_smote)\n",
    "smote_rf_prauc = average_precision_score(y_val, y_pred_smote)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE Oversampling</td>\n",
       "      <td>0.757513</td>\n",
       "      <td>0.706963</td>\n",
       "      <td>0.731366</td>\n",
       "      <td>0.536797</td>\n",
       "      <td>0.877934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Random Forest with    Recall  Precision  F1 Score    PR AUC   ROC_AUC\n",
       "0  SMOTE Oversampling  0.757513   0.706963  0.731366  0.536797  0.877934"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(smote_rf_Recall, smote_rf_Precision, smote_rf_f1, smote_rf_prauc, smote_rf_rocauc)]\n",
    "\n",
    "smote_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'PR AUC', 'ROC_AUC'])\n",
    "smote_rf_score.insert(0, 'Random Forest with', 'SMOTE Oversampling')\n",
    "smote_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: The proportion of actual positive cases correctly identified by the model is 75.75%. This indicates that the model is effective at capturing fraudulent transactions.\n",
    "\n",
    "Precision: Out of all the predicted positive cases, 70.70% are true positive. This measures the accuracy of the model when it predicts a transaction as fraudulent.\n",
    "\n",
    "F1 Score: The harmonic mean of precision and recall is 73.14%. It provides a balance between precision and recall.\n",
    "\n",
    "PR AUC (Precision-Recall Area Under the Curve): This metric is 53.68%. It summarizes the precision-recall trade-off; higher values are desirable.\n",
    "\n",
    "ROC AUC (Receiver Operating Characteristic Area Under the Curve): This metric is 87.79%. It evaluates the model's ability to distinguish between classes; higher values are better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch for SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = {'randomforestclassifier__' + key: params[key] for key in params}\n",
    "smote2_rf = GridSearchCV(smote_pipeline, param_grid=new_params, cv=kf, scoring='f1',\n",
    "                        return_train_score=True)\n",
    "smote2_rf.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'randomforestclassifier__max_depth': 12, 'randomforestclassifier__n_estimators': 200, 'randomforestclassifier__random_state': 13}\n",
      "Best score: 0.8752243571494269\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters:', smote2_rf.best_params_)\n",
    "print('Best score:', smote2_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best parameters for SMOTE from your grid search\n",
    "# best_params_smote = {\n",
    "#     'max_depth': 12,\n",
    "#     'n_estimators': 200,\n",
    "#     'random_state': 13\n",
    "# }\n",
    "\n",
    "# # Create a RandomForestClassifier with the best parameters for SMOTE\n",
    "# best_rf_smote = RandomForestClassifier(**best_params_smote)\n",
    "\n",
    "# # Fit the classifier on your training data for SMOTE\n",
    "# best_rf_smote.fit(X_train_final, y_train)  # Assuming you have a SMOTE augmented training set\n",
    "\n",
    "# # Make predictions on your val set for SMOTE\n",
    "# y_pred_smote2 = best_rf_smote.predict(X_val_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_smote2 = smote2_rf.best_estimator_.named_steps['randomforestclassifier'].predict(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[184225     49]\n",
      " [   513    452]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val, y_pred_smote2)\n",
    "\n",
    "smote2_rf_Recall = recall_score(y_val, y_pred_smote2)\n",
    "smote2_rf_Precision = precision_score(y_val, y_pred_smote2)\n",
    "smote2_rf_f1 = f1_score(y_val, y_pred_smote2)\n",
    "smote2_rf_accuracy = accuracy_score(y_val, y_pred_smote2)\n",
    "smote2_rf_rocauc = roc_auc_score(y_val, y_pred_smote2)\n",
    "smote2_rf_prauc = average_precision_score(y_val, y_pred_smote2)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE Oversampling using GridSearch</td>\n",
       "      <td>0.468394</td>\n",
       "      <td>0.902196</td>\n",
       "      <td>0.616644</td>\n",
       "      <td>0.425352</td>\n",
       "      <td>0.734064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Random Forest with    Recall  Precision  F1 Score  \\\n",
       "0  SMOTE Oversampling using GridSearch  0.468394   0.902196  0.616644   \n",
       "\n",
       "     PR AUC   ROC_AUC  \n",
       "0  0.425352  0.734064  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(smote2_rf_Recall, smote2_rf_Precision, smote2_rf_f1, smote2_rf_prauc, smote2_rf_rocauc)]\n",
    "\n",
    "smote2_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'PR AUC', 'ROC_AUC'])\n",
    "smote2_rf_score.insert(0, 'Random Forest with', 'SMOTE Oversampling using GridSearch')\n",
    "smote2_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: The recall is 46.84%. This indicates that the model correctly identifies about 46.84% of the actual positive cases. It's a measure of the model's ability to capture fraudulent transactions.\n",
    "\n",
    "Precision: The precision is 90.22%. Out of all the predicted positive cases, approximately 90.22% are true positives. This indicates a high accuracy when the model predicts a transaction as fraudulent.\n",
    "\n",
    "F1 Score: The F1 score is 61.66%. It represents the harmonic mean of precision and recall, providing a balanced measure of the model's performance.\n",
    "\n",
    "PR AUC (Precision-Recall Area Under the Curve): The PR AUC is 42.54%. It summarizes the precision-recall trade-off; higher values are desirable.\n",
    "\n",
    "ROC AUC (Receiver Operating Characteristic Area Under the Curve): The ROC AUC is 73.41%. It evaluates the model's ability to distinguish between classes; higher values are better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfb = RandomForestClassifier(n_estimators=100, random_state=13, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Recall scores are: [0.62990377 0.64248705 0.60547742 0.65136936 0.62130178]\n",
      "Average Cross Validation Recall score: 0.6301078753848781\n"
     ]
    }
   ],
   "source": [
    "score5 = cross_val_score(rfb, X_train_final, y_train, cv=kf, scoring='recall')\n",
    "print(\"Cross Validation Recall scores are: {}\".format(score5))\n",
    "print(\"Average Cross Validation Recall score: {}\".format(score5.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " model correctly identifies about 63.01% of the actual positive instances in the training data across different folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=13)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" checked><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, random_state=13)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', random_state=13)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfb.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_balanced = rfb.predict(X_val_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[184182     92]\n",
      " [   339    626]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val, y_pred_balanced)\n",
    "\n",
    "balaned_rf_Recall = recall_score(y_val, y_pred_balanced)\n",
    "balaned_rf_Precision = precision_score(y_val, y_pred_balanced)\n",
    "balaned_rf_f1 = f1_score(y_val, y_pred_balanced)\n",
    "balaned_rf_accuracy = accuracy_score(y_val, y_pred_balanced)\n",
    "balaned_rf_rocauc = roc_auc_score(y_val, y_pred_balanced)\n",
    "balanced_rf_prauc = average_precision_score(y_val, y_pred_balanced)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balanced Class Weights</td>\n",
       "      <td>0.648705</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.74391</td>\n",
       "      <td>0.567414</td>\n",
       "      <td>0.824103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Random Forest with    Recall  Precision  F1 Score    PR AUC   ROC_AUC\n",
       "0  Balanced Class Weights  0.648705   0.871866   0.74391  0.567414  0.824103"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(balaned_rf_Recall, balaned_rf_Precision, balaned_rf_f1, balanced_rf_prauc, balaned_rf_rocauc)]\n",
    "\n",
    "balanced_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'PR AUC', 'ROC_AUC'])\n",
    "balanced_rf_score.insert(0, 'Random Forest with', 'Balanced Class Weights')\n",
    "balanced_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: The recall is 64.87%. This indicates that the model correctly identifies about 64.87% of the actual positive cases. It's a measure of the model's ability to capture fraudulent transactions.\n",
    "\n",
    "Precision: The precision is 87.19%. Out of all the predicted positive cases, approximately 87.19% are true positives. This indicates a high accuracy when the model predicts a transaction as fraudulent.\n",
    "\n",
    "F1 Score: The F1 score is 74.39%. It represents the harmonic mean of precision and recall, providing a balanced measure of the model's performance.\n",
    "\n",
    "PR AUC (Precision-Recall Area Under the Curve): The PR AUC is 56.74%. It summarizes the precision-recall trade-off; higher values are desirable.\n",
    "\n",
    "ROC AUC (Receiver Operating Characteristic Area Under the Curve): The ROC AUC is 82.41%. It evaluates the model's ability to distinguish between classes; higher values are better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GridSearch for Balanced Class Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_rf_pipeline = Pipeline([\n",
    "    ('randomforestclassifier', RandomForestClassifier(random_state=13, class_weight=\"balanced\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'randomforestclassifier__max_depth': 12, 'randomforestclassifier__n_estimators': 200, 'randomforestclassifier__random_state': 13}\n"
     ]
    }
   ],
   "source": [
    "new_params = {'randomforestclassifier__' + key: params[key] for key in params}\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=balanced_rf_pipeline, param_grid=new_params, cv=3, scoring='f1')\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_final, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_balanced_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# You can use the best model for predictions on your test data\n",
    "y_pred_balanced2 = best_balanced_rf_model.predict(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Best parameters for SMOTE from your grid search\n",
    "# best_params_balanced = {\n",
    "#     'max_depth': 12,\n",
    "#     'n_estimators': 200,\n",
    "#     'random_state': 13\n",
    "# }\n",
    "\n",
    "# # Create a RandomForestClassifier with the best parameters for SMOTE\n",
    "# best_rf_balanced = RandomForestClassifier(**best_params_balanced)\n",
    "\n",
    "# # Fit the classifier on your training data for SMOTE\n",
    "# best_rf_balanced.fit(X_train_final, y_train)  # Assuming you have a SMOTE augmented training set\n",
    "\n",
    "# # Make predictions on your test set for SMOTE\n",
    "# y_pred_balanced2 = best_rf_balanced.predict(X_val_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[184225     49]\n",
      " [   513    452]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_val, y_pred_balanced2)\n",
    "\n",
    "balanced2_Recall = recall_score(y_val, y_pred_balanced2)\n",
    "balanced2_Precision = precision_score(y_val, y_pred_balanced2)\n",
    "balanced2_f1 = f1_score(y_val, y_pred_balanced2)\n",
    "balanced2_accuracy = accuracy_score(y_val, y_pred_balanced2)\n",
    "balanced2_roc = roc_auc_score(y_val, y_pred_balanced2)\n",
    "balanced2_rf_prauc = average_precision_score(y_val, y_pred_balanced2)\n",
    "\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balanced Class Weights using GridSearch</td>\n",
       "      <td>0.468394</td>\n",
       "      <td>0.902196</td>\n",
       "      <td>0.616644</td>\n",
       "      <td>0.425352</td>\n",
       "      <td>0.734064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Random Forest with    Recall  Precision  F1 Score  \\\n",
       "0  Balanced Class Weights using GridSearch  0.468394   0.902196  0.616644   \n",
       "\n",
       "     PR AUC   ROC_AUC  \n",
       "0  0.425352  0.734064  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(balanced2_Recall, balanced2_Precision, balanced2_f1, balanced2_rf_prauc, balanced2_roc)]\n",
    "\n",
    "balanced2_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'PR AUC', 'ROC_AUC'])\n",
    "balanced2_rf_score.insert(0, 'Random Forest with', 'Balanced Class Weights using GridSearch')\n",
    "balanced2_rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall: The recall is 46.84%. This indicates that the model correctly identifies about 46.84% of the actual positive cases. It's a measure of the model's ability to capture fraudulent transactions.\n",
    "\n",
    "Precision: The precision is 90.22%. Out of all the predicted positive cases, approximately 90.22% are true positives. This indicates a high accuracy when the model predicts a transaction as fraudulent.\n",
    "\n",
    "F1 Score: The F1 score is 61.66%. It represents the harmonic mean of precision and recall, providing a balanced measure of the model's performance.\n",
    "\n",
    "PR AUC (Precision-Recall Area Under the Curve): The PR AUC is 42.54%. It summarizes the precision-recall trade-off; higher values are desirable.\n",
    "\n",
    "ROC AUC (Receiver Operating Characteristic Area Under the Curve): The ROC AUC is 73.41%. It evaluates the model's ability to distinguish between classes; higher values are better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Oversampling</td>\n",
       "      <td>0.709845</td>\n",
       "      <td>0.804935</td>\n",
       "      <td>0.754405</td>\n",
       "      <td>0.572891</td>\n",
       "      <td>0.854472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Under/Oversampling</td>\n",
       "      <td>0.662176</td>\n",
       "      <td>0.857718</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.569720</td>\n",
       "      <td>0.830800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Balanced Class Weights</td>\n",
       "      <td>0.648705</td>\n",
       "      <td>0.871866</td>\n",
       "      <td>0.743910</td>\n",
       "      <td>0.567414</td>\n",
       "      <td>0.824103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SMOTE Oversampling</td>\n",
       "      <td>0.757513</td>\n",
       "      <td>0.706963</td>\n",
       "      <td>0.731366</td>\n",
       "      <td>0.536797</td>\n",
       "      <td>0.877934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE Oversampling using GridSearch</td>\n",
       "      <td>0.468394</td>\n",
       "      <td>0.902196</td>\n",
       "      <td>0.616644</td>\n",
       "      <td>0.425352</td>\n",
       "      <td>0.734064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Balanced Class Weights using GridSearch</td>\n",
       "      <td>0.468394</td>\n",
       "      <td>0.902196</td>\n",
       "      <td>0.616644</td>\n",
       "      <td>0.425352</td>\n",
       "      <td>0.734064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Oversampling using GridSearch</td>\n",
       "      <td>0.860104</td>\n",
       "      <td>0.276114</td>\n",
       "      <td>0.418031</td>\n",
       "      <td>0.238216</td>\n",
       "      <td>0.924148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random undersampling using GridSearch</td>\n",
       "      <td>0.844560</td>\n",
       "      <td>0.220449</td>\n",
       "      <td>0.349635</td>\n",
       "      <td>0.238216</td>\n",
       "      <td>0.914460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Undersampling</td>\n",
       "      <td>0.960622</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.242734</td>\n",
       "      <td>0.133653</td>\n",
       "      <td>0.964720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Random Forest with    Recall  Precision  F1 Score  \\\n",
       "8                      Random Oversampling  0.709845   0.804935  0.754405   \n",
       "0                    No Under/Oversampling  0.662176   0.857718  0.747368   \n",
       "5                   Balanced Class Weights  0.648705   0.871866  0.743910   \n",
       "7                       SMOTE Oversampling  0.757513   0.706963  0.731366   \n",
       "2      SMOTE Oversampling using GridSearch  0.468394   0.902196  0.616644   \n",
       "4  Balanced Class Weights using GridSearch  0.468394   0.902196  0.616644   \n",
       "3     Random Oversampling using GridSearch  0.860104   0.276114  0.418031   \n",
       "1    Random undersampling using GridSearch  0.844560   0.220449  0.349635   \n",
       "6                     Random Undersampling  0.960622   0.138918  0.242734   \n",
       "\n",
       "     PR AUC   ROC_AUC  \n",
       "8  0.572891  0.854472  \n",
       "0  0.569720  0.830800  \n",
       "5  0.567414  0.824103  \n",
       "7  0.536797  0.877934  \n",
       "2  0.425352  0.734064  \n",
       "4  0.425352  0.734064  \n",
       "3  0.238216  0.924148  \n",
       "1  0.238216  0.914460  \n",
       "6  0.133653  0.964720  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.concat([rf_score, under2_rf_score, smote2_rf_score, over2_rf_score, balanced2_rf_score, balanced_rf_score, under_rf_score, smote_rf_score, over_rf_score], ignore_index=True, sort=False)\n",
    "predictions.sort_values(by=['F1 Score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results above, we can see that random oversampling performed slightly better than the base model while the other models are not as good. We can now evaluate the random oversampling model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_overs_pipeline = make_pipeline(RandomOverSampler(random_state=42), \n",
    "                              RandomForestClassifier(n_estimators=100, random_state=13))\n",
    "#cross_val_score(random_overs_pipeline, X_train, y_train, scoring='recall', cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_overs_pipeline.fit(X_over, y_over)\n",
    "\n",
    "y_pred_best = random_overs_pipeline.predict(X_test_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[184081    194]\n",
      " [   286    679]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "\n",
    "best_rf_Recall = recall_score(y_test, y_pred_best)\n",
    "best_rf_Precision = precision_score(y_test, y_pred_best)\n",
    "best_rf_f1 = f1_score(y_test, y_pred_best)\n",
    "best_rf_accuracy = accuracy_score(y_test, y_pred_best)\n",
    "best_roc = roc_auc_score(y_test, y_pred_best)\n",
    "best_prauc = average_precision_score(y_test, y_pred_best)\n",
    "\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Oversampling (Best)</td>\n",
       "      <td>0.703627</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.738847</td>\n",
       "      <td>0.548809</td>\n",
       "      <td>0.851287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Random Forest with    Recall  Precision  F1 Score    PR AUC  \\\n",
       "0  Random Oversampling (Best)  0.703627   0.777778  0.738847  0.548809   \n",
       "\n",
       "    ROC_AUC  \n",
       "0  0.851287  "
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = [(best_rf_Recall, best_rf_Precision, best_rf_f1, best_prauc, best_roc)]\n",
    "\n",
    "best_rf_score = pd.DataFrame(data = ndf, columns=['Recall','Precision','F1 Score', 'PR AUC', 'ROC_AUC'])\n",
    "best_rf_score.insert(0, 'Random Forest with', 'Random Oversampling (Best)')\n",
    "best_rf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Random Forest with</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>PR AUC</th>\n",
       "      <th>ROC_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Under/Oversampling</td>\n",
       "      <td>0.662176</td>\n",
       "      <td>0.857718</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.569720</td>\n",
       "      <td>0.830800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Oversampling (Best)</td>\n",
       "      <td>0.703627</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.738847</td>\n",
       "      <td>0.548809</td>\n",
       "      <td>0.851287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Random Forest with    Recall  Precision  F1 Score    PR AUC  \\\n",
       "0       No Under/Oversampling  0.662176   0.857718  0.747368  0.569720   \n",
       "1  Random Oversampling (Best)  0.703627   0.777778  0.738847  0.548809   \n",
       "\n",
       "    ROC_AUC  \n",
       "0  0.830800  \n",
       "1  0.851287  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.concat([rf_score, best_rf_score], ignore_index=True, sort=False)\n",
    "predictions.sort_values(by=['F1 Score'], ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
