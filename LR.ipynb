{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from random import seed,sample\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from imblearn.under_sampling import RandomUnderSampler # Undersampling for Unbalanced Data\n",
    "from imblearn.over_sampling import SMOTE # Oversampling for Unbalanced Data\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler # Data Encoders\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('../X_train.csv')\n",
    "X_test = pd.read_csv('../X_test.csv')\n",
    "y_train = pd.read_csv('../y_train.csv')\n",
    "y_test = pd.read_csv('../y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1296675 entries, 0 to 1296674\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count    Dtype\n",
      "---  ------    --------------    -----\n",
      " 0   is_fraud  1296675 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 9.9 MB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features below only, we don't scale the hour_of_day since the values are already within a similar range and have a clear numerical interpretation (hours of the day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 555719 entries, 0 to 555718\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   category     555719 non-null  object \n",
      " 1   amount(usd)  555719 non-null  float64\n",
      " 2   gender       555719 non-null  object \n",
      " 3   state        555719 non-null  object \n",
      " 4   lat          555719 non-null  float64\n",
      " 5   long         555719 non-null  float64\n",
      " 6   job          555719 non-null  object \n",
      " 7   merch_lat    555719 non-null  float64\n",
      " 8   merch_long   555719 non-null  float64\n",
      " 9   hour_of_day  555719 non-null  int64  \n",
      " 10  day_of_week  555719 non-null  object \n",
      " 11  age          555719 non-null  float64\n",
      "dtypes: float64(6), int64(1), object(5)\n",
      "memory usage: 50.9+ MB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features_to_scale = [\"amount(usd)\", \"lat\", \"long\", \"merch_lat\", \"merch_long\", \"age\"]\n",
    "\n",
    "\n",
    "# Initialize the StandardScaler and fit/transform on numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the scaler on the selected features in your training data\n",
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])\n",
    "\n",
    "# Transform the same selected features in your test data using the same scaler\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])\n",
    "\n",
    "X_test_scaled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>amount(usd)</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>job</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>health_fitness</td>\n",
       "      <td>0.272269</td>\n",
       "      <td>M</td>\n",
       "      <td>AL</td>\n",
       "      <td>-0.899089</td>\n",
       "      <td>0.267408</td>\n",
       "      <td>Aid worker</td>\n",
       "      <td>-0.849623</td>\n",
       "      <td>0.212847</td>\n",
       "      <td>14</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>-0.184877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>misc_pos</td>\n",
       "      <td>-0.414741</td>\n",
       "      <td>F</td>\n",
       "      <td>CA</td>\n",
       "      <td>-0.870119</td>\n",
       "      <td>-2.009787</td>\n",
       "      <td>Civil Service fast streamer</td>\n",
       "      <td>-0.984834</td>\n",
       "      <td>-1.957631</td>\n",
       "      <td>8</td>\n",
       "      <td>Monday</td>\n",
       "      <td>-0.587264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shopping_pos</td>\n",
       "      <td>-0.397939</td>\n",
       "      <td>F</td>\n",
       "      <td>SC</td>\n",
       "      <td>-0.888289</td>\n",
       "      <td>0.583966</td>\n",
       "      <td>Research scientist (physical sciences)</td>\n",
       "      <td>-0.842206</td>\n",
       "      <td>0.640575</td>\n",
       "      <td>18</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>-0.644748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shopping_net</td>\n",
       "      <td>-0.399281</td>\n",
       "      <td>F</td>\n",
       "      <td>MN</td>\n",
       "      <td>1.773167</td>\n",
       "      <td>-0.418025</td>\n",
       "      <td>Applications developer</td>\n",
       "      <td>1.686301</td>\n",
       "      <td>-0.489843</td>\n",
       "      <td>7</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0.447446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>0.182959</td>\n",
       "      <td>M</td>\n",
       "      <td>OH</td>\n",
       "      <td>0.445917</td>\n",
       "      <td>0.644181</td>\n",
       "      <td>Building control surveyor</td>\n",
       "      <td>0.264207</td>\n",
       "      <td>0.612831</td>\n",
       "      <td>3</td>\n",
       "      <td>Friday</td>\n",
       "      <td>0.619897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category  amount(usd) gender state       lat      long  \\\n",
       "0  health_fitness     0.272269      M    AL -0.899089  0.267408   \n",
       "1        misc_pos    -0.414741      F    CA -0.870119 -2.009787   \n",
       "2    shopping_pos    -0.397939      F    SC -0.888289  0.583966   \n",
       "3    shopping_net    -0.399281      F    MN  1.773167 -0.418025   \n",
       "4     grocery_pos     0.182959      M    OH  0.445917  0.644181   \n",
       "\n",
       "                                      job  merch_lat  merch_long  hour_of_day  \\\n",
       "0                              Aid worker  -0.849623    0.212847           14   \n",
       "1             Civil Service fast streamer  -0.984834   -1.957631            8   \n",
       "2  Research scientist (physical sciences)  -0.842206    0.640575           18   \n",
       "3                  Applications developer   1.686301   -0.489843            7   \n",
       "4               Building control surveyor   0.264207    0.612831            3   \n",
       "\n",
       "  day_of_week       age  \n",
       "0     Tuesday -0.184877  \n",
       "1      Monday -0.587264  \n",
       "2    Saturday -0.644748  \n",
       "3      Monday  0.447446  \n",
       "4      Friday  0.619897  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of unqiue sates:  51\n",
      "no of unqiue categories:  14\n",
      "no of unqiue jobs:  495\n"
     ]
    }
   ],
   "source": [
    "unqiue_state = X_test_scaled['state'].nunique()\n",
    "unique_category = X_test_scaled['category'].nunique()\n",
    "unique_job = X_test_scaled['job'].nunique()\n",
    "\n",
    "print(\"no of unqiue sates: \", unqiue_state)\n",
    "print(\"no of unqiue categories: \", unique_category)\n",
    "print(\"no of unqiue jobs: \", unique_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then be one hot encoding some of our categorical variables to run a logistic regression model on X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize the OneHotEncoder with sparse=False and drop='first'\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "\n",
    "# Fit and transform the encoder on categorical columns in the training data\n",
    "X_train_encoded = encoder.fit_transform(X_train_scaled[['category', 'gender', 'day_of_week']])\n",
    "\n",
    "# Transform the same columns in the test data\n",
    "X_test_encoded = encoder.transform(X_test_scaled[['category', 'gender', 'day_of_week']])\n",
    "\n",
    "# Create DataFrames from the encoded arrays with appropriate column names\n",
    "encoded_columns = encoder.get_feature_names_out(['category', 'gender', 'day_of_week'])\n",
    "X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=encoded_columns)\n",
    "X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=encoded_columns)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final = pd.concat([X_train_encoded_df, X_train_scaled[['age', 'lat', 'long', 'amount(usd)']]], axis=1)\n",
    "X_test_final = pd.concat([X_test_encoded_df, X_test_scaled[['age', 'lat', 'long', 'amount(usd)']]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_food_dining</th>\n",
       "      <th>category_gas_transport</th>\n",
       "      <th>category_grocery_net</th>\n",
       "      <th>category_grocery_pos</th>\n",
       "      <th>category_health_fitness</th>\n",
       "      <th>category_home</th>\n",
       "      <th>category_kids_pets</th>\n",
       "      <th>category_misc_net</th>\n",
       "      <th>category_misc_pos</th>\n",
       "      <th>category_personal_care</th>\n",
       "      <th>category_shopping_net</th>\n",
       "      <th>category_shopping_pos</th>\n",
       "      <th>category_travel</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>day_of_week_Monday</th>\n",
       "      <th>day_of_week_Saturday</th>\n",
       "      <th>day_of_week_Sunday</th>\n",
       "      <th>day_of_week_Thursday</th>\n",
       "      <th>day_of_week_Tuesday</th>\n",
       "      <th>day_of_week_Wednesday</th>\n",
       "      <th>age</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>amount(usd)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.529780</td>\n",
       "      <td>-1.017905</td>\n",
       "      <td>-0.697973</td>\n",
       "      <td>-0.049452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.242361</td>\n",
       "      <td>-0.899089</td>\n",
       "      <td>0.267408</td>\n",
       "      <td>-0.411866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.516865</td>\n",
       "      <td>-0.180855</td>\n",
       "      <td>-0.513891</td>\n",
       "      <td>-0.384140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.194736</td>\n",
       "      <td>0.870670</td>\n",
       "      <td>0.939560</td>\n",
       "      <td>-0.407203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160026</td>\n",
       "      <td>0.171946</td>\n",
       "      <td>0.697850</td>\n",
       "      <td>-0.315082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_food_dining  category_gas_transport  category_grocery_net  \\\n",
       "0                   0.0                     1.0                   0.0   \n",
       "1                   0.0                     0.0                   0.0   \n",
       "2                   0.0                     0.0                   0.0   \n",
       "3                   0.0                     0.0                   0.0   \n",
       "4                   0.0                     0.0                   0.0   \n",
       "\n",
       "   category_grocery_pos  category_health_fitness  category_home  \\\n",
       "0                   0.0                      0.0            0.0   \n",
       "1                   0.0                      0.0            0.0   \n",
       "2                   0.0                      0.0            0.0   \n",
       "3                   0.0                      0.0            0.0   \n",
       "4                   0.0                      0.0            0.0   \n",
       "\n",
       "   category_kids_pets  category_misc_net  category_misc_pos  \\\n",
       "0                 0.0                0.0                0.0   \n",
       "1                 0.0                0.0                1.0   \n",
       "2                 0.0                0.0                0.0   \n",
       "3                 0.0                0.0                0.0   \n",
       "4                 0.0                0.0                0.0   \n",
       "\n",
       "   category_personal_care  category_shopping_net  category_shopping_pos  \\\n",
       "0                     0.0                    0.0                    0.0   \n",
       "1                     0.0                    0.0                    0.0   \n",
       "2                     0.0                    0.0                    1.0   \n",
       "3                     1.0                    0.0                    0.0   \n",
       "4                     0.0                    0.0                    0.0   \n",
       "\n",
       "   category_travel  gender_M  day_of_week_Monday  day_of_week_Saturday  \\\n",
       "0              0.0       0.0                 0.0                   1.0   \n",
       "1              0.0       1.0                 0.0                   0.0   \n",
       "2              0.0       0.0                 0.0                   0.0   \n",
       "3              0.0       1.0                 0.0                   0.0   \n",
       "4              0.0       0.0                 0.0                   0.0   \n",
       "\n",
       "   day_of_week_Sunday  day_of_week_Thursday  day_of_week_Tuesday  \\\n",
       "0                 0.0                   0.0                  0.0   \n",
       "1                 0.0                   0.0                  0.0   \n",
       "2                 0.0                   0.0                  0.0   \n",
       "3                 1.0                   0.0                  0.0   \n",
       "4                 0.0                   0.0                  1.0   \n",
       "\n",
       "   day_of_week_Wednesday       age       lat      long  amount(usd)  \n",
       "0                    0.0 -0.529780 -1.017905 -0.697973    -0.049452  \n",
       "1                    0.0 -0.242361 -0.899089  0.267408    -0.411866  \n",
       "2                    1.0  2.516865 -0.180855 -0.513891    -0.384140  \n",
       "3                    0.0  1.194736  0.870670  0.939560    -0.407203  \n",
       "4                    0.0  0.160026  0.171946  0.697850    -0.315082  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with NaN values in X_train_final: Index([], dtype='object')\n",
      "Columns with NaN values in X_test_final: Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in each column of X_train_final\n",
    "nan_columns_train = X_train_final.columns[X_train_final.isna().any()]\n",
    "\n",
    "# Check for NaN values in each column of X_test_final\n",
    "nan_columns_test = X_test_final.columns[X_test_final.isna().any()]\n",
    "\n",
    "# Print the columns with NaN values for both datasets\n",
    "print(\"Columns with NaN values in X_train_final:\", nan_columns_train)\n",
    "print(\"Columns with NaN values in X_test_final:\", nan_columns_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in X: 1296675\n",
      "Number of rows in y: 1296675\n"
     ]
    }
   ],
   "source": [
    "# Display the number of rows in X\n",
    "print(\"Number of rows in X:\", len(X_train_final))\n",
    "\n",
    "# Display the number of rows in y\n",
    "print(\"Number of rows in y:\", len(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run logistic regression model to predict on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    552824\n",
      "           1       0.00      0.00      0.00      2895\n",
      "\n",
      "    accuracy                           0.99    555719\n",
      "   macro avg       0.50      0.50      0.50    555719\n",
      "weighted avg       0.99      0.99      0.99    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logistic_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "logistic_reg.fit(X_train_final, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = logistic_reg.predict(X_test_final)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision for class 1 (fraud) is 0.00, meaning that the model is making many false positive predictions. In other words, when it predicts a transaction as fraud, it's often incorrect. Recall for class 1 (fraud) is also 0.00, indicating that the model is unable to capture most of the actual fraudulent transactions. It's making many false negative errors. The F1-score for class 1 is 0.00, which is the harmonic mean of precision and recall. It's low due to the poor precision and recall.\n",
    "\n",
    "These results are likely a consequence of the class imbalance issue. The model is biased toward the majority class (non-fraudulent transactions) because there are significantly more instances of that class in the dataset. As a result, the model tends to predict the majority class and perform poorly on the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try to apply SMOTE to our logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SMOTE with the desired sampling strategy \n",
    "smote = SMOTE(sampling_strategy=1.0, random_state=42)\n",
    "\n",
    "# Resample the training data using SMOTE\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_final, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non fraudulent counts before SMOTE: 1289919\n",
      "Number of fraudulent counts before SMOTE: 6756\n",
      "Number of non fraudulent counts after SMOTE: 1289919\n",
      "Number of fraudulent counts after SMOTE: 1289919\n"
     ]
    }
   ],
   "source": [
    "fraudulent_before = y_train.value_counts()[1]\n",
    "non_fraudulent_before = len(y_train) - fraudulent_before\n",
    "fraudulent_after = y_train_resampled.value_counts()[1]\n",
    "non_fraudulent_after = len(y_train_resampled) - fraudulent_after\n",
    "print(\"Number of non fraudulent counts before SMOTE:\", non_fraudulent_before)\n",
    "print(\"Number of fraudulent counts before SMOTE:\", fraudulent_before)\n",
    "print(\"Number of non fraudulent counts after SMOTE:\", non_fraudulent_after)\n",
    "print(\"Number of fraudulent counts after SMOTE:\", fraudulent_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94    552824\n",
      "           1       0.03      0.76      0.06      2895\n",
      "\n",
      "    accuracy                           0.88    555719\n",
      "   macro avg       0.52      0.82      0.50    555719\n",
      "weighted avg       0.99      0.88      0.93    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the logistic regression model\n",
    "logistic_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fit the model on the resampled training data\n",
    "logistic_reg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = logistic_reg.predict(X_test_final)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like SMOTE has helped improve the recall for the positive class (fraudulent transactions), but there is still room for improvement in precision. Here's a summary of the classification report:\n",
    "\n",
    "For class 0 (non-fraudulent transactions), the precision is high (1.00), meaning that when the model predicts a transaction as non-fraudulent, it's usually correct. However, the recall is relatively low (0.88), which suggests that the model may miss some non-fraudulent transactions.\n",
    "\n",
    "For class 1 (fraudulent transactions), the precision is very low (0.03), meaning that when the model predicts a transaction as fraudulent, it's often incorrect. The recall is higher (0.76), indicating that the model is better at identifying fraudulent transactions.\n",
    "\n",
    "The overall accuracy is 0.88, which is relatively high, but it might be due to the class imbalance, where the majority of transactions are non-fraudulent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try RandomOversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Initialize RandomOverSampler with the desired sampling strategy\n",
    "ros = RandomOverSampler(sampling_strategy=1.0, random_state=42)\n",
    "\n",
    "# Resample the training data using RandomOverSampler\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_final, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_before = y_train.value_counts()[1]\n",
    "non_fraudulent_before = len(y_train) - fraudulent_before\n",
    "fraudulent_after = y_train_resampled.value_counts()[1]\n",
    "non_fraudulent_after = len(y_train_resampled) - fraudulent_after\n",
    "print(\"Number of non fraudulent counts before RandomOversampler:\", non_fraudulent_before)\n",
    "print(\"Number of fraudulent counts before RandomOversampler:\", fraudulent_before)\n",
    "print(\"Number of non fraudulent counts after RandomOversampler:\", non_fraudulent_after)\n",
    "print(\"Number of fraudulent counts after RandomOversampler:\", fraudulent_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94    552824\n",
      "           1       0.04      0.76      0.07      2895\n",
      "\n",
      "    accuracy                           0.89    555719\n",
      "   macro avg       0.52      0.82      0.50    555719\n",
      "weighted avg       0.99      0.89      0.94    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the logistic regression model\n",
    "logistic_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fit the model on the resampled training data\n",
    "logistic_reg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = logistic_reg.predict(X_test_final)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best class weights ratio to use and apply the class weights to compensate for the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Weight Ratio: 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.85    552824\n",
      "           1       0.02      0.85      0.03      2895\n",
      "\n",
      "    accuracy                           0.73    555719\n",
      "   macro avg       0.51      0.79      0.44    555719\n",
      "weighted avg       0.99      0.73      0.84    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create a parameter grid with different weight ratios to test\n",
    "param_grid = {'class_weight': [{0: 1.0, 1: weight_ratio} for weight_ratio in range(1, 11)]}\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "logistic_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=logistic_reg, param_grid=param_grid, scoring='f1', cv=3)\n",
    "\n",
    "# Fit the model with grid search on the resampled training data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_weight_ratio = grid_search.best_params_['class_weight'][1]\n",
    "\n",
    "# Initialize the logistic regression model with the best weight ratio\n",
    "best_logistic_reg = LogisticRegression(class_weight={0: 1.0, 1: best_weight_ratio}, random_state=42)\n",
    "\n",
    "# Fit the model on the resampled training data with the best weight ratio\n",
    "best_logistic_reg.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_logistic_reg.predict(X_test_final)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Best Weight Ratio:\", best_weight_ratio)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune hyperparameters for log regression, find the best parameter using grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy='minority', random_state=42)\n",
    "\n",
    "# Resample the training data using SMOTE\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_final, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;], &#x27;solver&#x27;: [&#x27;liblinear&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;], &#x27;solver&#x27;: [&#x27;liblinear&#x27;]},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2'], 'solver': ['liblinear']},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "logistic_reg = LogisticRegression(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=logistic_reg, param_grid=param_grid, scoring='f1', cv=5)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_logistic_reg = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_logistic_reg.predict(X_test_final)\n",
    "# Calculate and print performance metrics (e.g., precision, recall, F1, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.03386602248443742\n",
      "Recall: 0.755440414507772\n",
      "F1-score: 0.06482593037214887\n",
      "Accuracy: 0.8864552048787246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94    552824\n",
      "           1       0.03      0.76      0.06      2895\n",
      "\n",
      "    accuracy                           0.89    555719\n",
      "   macro avg       0.52      0.82      0.50    555719\n",
      "weighted avg       0.99      0.89      0.94    555719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results generated are still similar to as the ones before, indicating that even after hyperparameter tuning, the logistic regression model is struggling to correctly classify the minority class (fraudulent transactions)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
